{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Learning with Pixano - MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> initialize vital variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration variables\n",
    "DATASET_NAME=\"MNIST_pixano_v8\"\n",
    "customLearnerCondaEnv=\"customLearner3\"\n",
    "\n",
    "# variables that could be defined \n",
    "labels_per_round=100\n",
    "round = 0 # current round\n",
    "learning_rate=0.001\n",
    "max_epochs_per_round=100\n",
    "model_name=\"mlp\" \n",
    "strategy=\"AlphaMixSampling\" #EntropySampling #RandomSampling\n",
    "alpha_opt=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> import ROOT dir to import pixano root module , which is the pixano directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/melissap/Desktop/LAGO_43integrationDemo/pixano/ActiveLearning/certh_integration/231031_mnist\n",
      "/home/melissap/Desktop/LAGO_43integrationDemo/pixano/ActiveLearning/certh_integration\n",
      "/home/melissap/Desktop/LAGO_43integrationDemo/pixano/ActiveLearning\n",
      "Inserting parent dir :  /home/melissap/Desktop/LAGO_43integrationDemo/pixano\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "def insertRootDir(ROOTDIR='pixano'):\n",
    "    pardir=os.path.dirname(os.path.realpath('__file__'))\n",
    "\n",
    "    while(os.path.basename(pardir)!=ROOTDIR):\n",
    "\n",
    "        print(pardir)\n",
    "        pardir=os.path.dirname(pardir)\n",
    "        # print(os.path.basename(pardir))\n",
    "    print(\"Inserting parent dir : \",pardir)\n",
    "    sys.path.insert(0,pardir)\n",
    "    return pardir\n",
    "\n",
    "ROOTDIR = insertRootDir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pixano.data import ImageImporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "library_dir=Path('/home/melissap/_pixano_datasets_') # directory where we have install the pixano formatted dataset\n",
    "import_dir = library_dir / DATASET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b76c576ae588431f9a0decfe9fa1af07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Importing dataset: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Generated dataset is empty. Please make sure that the paths to your media files are correct, and that they each contain subfolders for your splits.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/melissap/Desktop/LAGO_43integrationDemo/pixano/ActiveLearning/certh_integration/231031_mnist/4integrateAl.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B160.40.53.42/home/melissap/Desktop/LAGO_43integrationDemo/pixano/ActiveLearning/certh_integration/231031_mnist/4integrateAl.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Note: images have been generated by MNIST (v1) notebook, and moved here\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B160.40.53.42/home/melissap/Desktop/LAGO_43integrationDemo/pixano/ActiveLearning/certh_integration/231031_mnist/4integrateAl.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# TODO add a cell to generate image from mnist (from keras.datasets import mnist)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B160.40.53.42/home/melissap/Desktop/LAGO_43integrationDemo/pixano/ActiveLearning/certh_integration/231031_mnist/4integrateAl.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m mnist_importer \u001b[39m=\u001b[39m ImageImporter(\u001b[39m\"\u001b[39m\u001b[39mMNIST\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mMNIST dataset for AL\u001b[39m\u001b[39m\"\u001b[39m, [\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B160.40.53.42/home/melissap/Desktop/LAGO_43integrationDemo/pixano/ActiveLearning/certh_integration/231031_mnist/4integrateAl.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m mnist_importer\u001b[39m.\u001b[39;49mimport_dataset(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B160.40.53.42/home/melissap/Desktop/LAGO_43integrationDemo/pixano/ActiveLearning/certh_integration/231031_mnist/4integrateAl.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     input_dirs\u001b[39m=\u001b[39;49m{ \u001b[39m\"\u001b[39;49m\u001b[39mimage\u001b[39;49m\u001b[39m\"\u001b[39;49m: IMG_PATH },\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B160.40.53.42/home/melissap/Desktop/LAGO_43integrationDemo/pixano/ActiveLearning/certh_integration/231031_mnist/4integrateAl.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     import_dir\u001b[39m=\u001b[39;49mDB_PATH,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B160.40.53.42/home/melissap/Desktop/LAGO_43integrationDemo/pixano/ActiveLearning/certh_integration/231031_mnist/4integrateAl.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     portable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B160.40.53.42/home/melissap/Desktop/LAGO_43integrationDemo/pixano/ActiveLearning/certh_integration/231031_mnist/4integrateAl.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/LAGO_43integrationDemo/pixano/pixano/data/importers/importer.py:237\u001b[0m, in \u001b[0;36mImporter.import_dataset\u001b[0;34m(self, input_dirs, import_dir, portable)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[39m# Raise error if generated dataset is empty\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(ds_tables[\u001b[39m\"\u001b[39m\u001b[39mmain\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mdb\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 237\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m    238\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mGenerated dataset is empty. Please make sure that the paths to your media files are correct, and that they each contain subfolders for your splits.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    239\u001b[0m     )\n\u001b[1;32m    241\u001b[0m \u001b[39m# Copy media directories if portable\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[39mif\u001b[39;00m portable \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmedia\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m ds_tables:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Generated dataset is empty. Please make sure that the paths to your media files are correct, and that they each contain subfolders for your splits."
     ]
    }
   ],
   "source": [
    "# TAKEN FROM THE MNIST.ipynb notebook\n",
    "# output path for lance database\n",
    "DB_PATH = library_dir / \"_launce_datasets_/MNIST\"\n",
    "# input image path\n",
    "IMG_PATH = import_dir / \"media\"\n",
    "# Note: images have been generated by MNIST (v1) notebook, and moved here\n",
    "# TODO add a cell to generate image from mnist (from keras.datasets import mnist)\n",
    "\n",
    "mnist_importer = ImageImporter(\"MNIST\", \"MNIST dataset for AL\", [\"train\", \"test\"])\n",
    "mnist_importer.import_dataset(\n",
    "    input_dirs={ \"image\": IMG_PATH },\n",
    "    import_dir=DB_PATH,\n",
    "    portable=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 14:03:31.673441: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import lancedb\n",
    "import pyarrow as pa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.datasets import mnist\n",
    "from ALearner import (\n",
    "    Learner,\n",
    "    BaseAnnotator,\n",
    "    BaseSampler,\n",
    "    BaseTrainer,\n",
    "    getLabels,\n",
    "    getLabelledIds,\n",
    "    getUnlabelledIds,\n",
    "    getTaggedIds,\n",
    "    getLastRound,\n",
    "    ddb_str,\n",
    "    custom_update\n",
    ")\n",
    "from pixano.utils import natural_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function to convert id (format \"<index>.png\") to index\n",
    "def id_to_idx(id: str) -> int:\n",
    "    return int(id.split(\".\")[0])\n",
    "    # return int(id[0:-4])  #remove the last 4 chars (\".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Pixano DB\n",
    "MNIST dataset should have been imported previously (see lance_importers/MNIST.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_db = lancedb.connect(import_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Trainer Object\n",
    "\n",
    "We will get raw x_train, x_test, y_test data directly from MNIST.\n",
    "\n",
    "2 proposed Model Trainer Objects, with same model: SimpleTrainer and IncrementalTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 14:03:55.360936: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "\n",
    "def reshape_Xdata(x):\n",
    "    #flatten images\n",
    "    x = x.reshape(x.shape[0], num_pixels)\n",
    "    #Convert to float\n",
    "    x = x.astype('float32')\n",
    "    #Normalize inputs from [0; 255] to [0; 1]\n",
    "    x = x / 255\n",
    "    return x\n",
    "\n",
    "def reshape_Ydata(y):\n",
    "    #Convert class vectors to binary class matrices (\"one hot encoding\")\n",
    "    ## Doc : https://keras.io/utils/#to_categorical\n",
    "    return keras.utils.to_categorical(y, num_classes=10)  # need to specify num_classes because sampler can miss some classes\n",
    "\n",
    "\n",
    "#x_train = reshape_Xdata(X_train)\n",
    "x_test = reshape_Xdata(X_test)\n",
    "y_train = reshape_Ydata(Y_train)\n",
    "y_test = reshape_Ydata(Y_test)\n",
    "num_classes = y_train.shape[1]\n",
    "\n",
    "def neural_network():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
    "    #model.add(Dropout(.5))\n",
    "    model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = neural_network()\n",
    "\n",
    "\n",
    "class SimpleTrainer(BaseTrainer):\n",
    "    # simple trainer, train on all labeled data\n",
    "    def __init__(self, db, model, validation_data, avoid_overfit=False):\n",
    "        self.init_weights = model.get_weights()\n",
    "        self.avoid_overfit = avoid_overfit\n",
    "        super().__init__(db, model, validation_data)\n",
    "\n",
    "    # training on subset data\n",
    "    def train(self, epochs, batch_size):\n",
    "        # get y data (labels) and ids from db, x data (images) from raw mnist and ids\n",
    "        ids = getLabelledIds(self.db)\n",
    "        labels = getLabels(self.db)\n",
    "        if self.avoid_overfit:\n",
    "            print(\"Reset weights to avoid overfit\")\n",
    "            self.model.set_weights(self.init_weights)\n",
    "        print(f\"Train on {len(ids)} labelled items\")\n",
    "        x_train = reshape_Xdata(np.array([X_train[id_to_idx(id)] for id in ids]))\n",
    "        y_train = reshape_Ydata(np.array(labels))\n",
    "        self.model.fit(x_train, y_train, validation_data=self.validation_data, epochs=epochs, batch_size=batch_size)\n",
    "        scores = model.evaluate(self.validation_data[0], self.validation_data[1])\n",
    "        print(\"Neural network accuracy: %.2f%%\" % (scores[1]*100))\n",
    "        return {\n",
    "            \"score\": scores[1]*100\n",
    "        }\n",
    "\n",
    "class IncrementalTrainer(BaseTrainer):\n",
    "    #in this trainer we train only on last round\n",
    "    def __init__(self, db, model, validation_data):\n",
    "        self.initial_epoch = 0\n",
    "        super().__init__(db, model, validation_data)\n",
    "\n",
    "    # training on subset data\n",
    "    def train(self, epochs, batch_size):\n",
    "        # get y data (labels) and ids from db, x data (images) from raw mnist and ids\n",
    "        round = getLastRound(self.db)\n",
    "        ids = getLabelledIds(self.db, round)\n",
    "        labels = getLabels(self.db, round)\n",
    "        print(f\"Train on {len(ids)} labelled items. initial epoch = {self.initial_epoch}\")\n",
    "        x_train = reshape_Xdata(np.array([X_train[id_to_idx(id)] for id in ids]))\n",
    "        y_train = reshape_Ydata(np.array(labels))\n",
    "        self.model.fit(x_train, y_train, validation_data=self.validation_data, epochs=self.initial_epoch+epochs, batch_size=batch_size, initial_epoch=self.initial_epoch)\n",
    "        scores = model.evaluate(self.validation_data[0], self.validation_data[1])\n",
    "        print(\"Neural network accuracy: %.2f%%\" % (scores[1]*100))\n",
    "        # update initial_epoch for next round\n",
    "        self.initial_epoch += epochs\n",
    "        return {\n",
    "            \"score\": scores[1]*100\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Sampler Object\n",
    "<!-- RandomSampler or SequentialSampler -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: ids (whole dataset, or filtered (here: train only))\n",
    "# output: candidates\n",
    "\n",
    "class RandomSampler(BaseSampler):\n",
    "\n",
    "    def query(self, n_candidates=10):\n",
    "        ids = getUnlabelledIds(self.db, split=\"train\")\n",
    "        return random.sample(ids, n_candidates)\n",
    "\n",
    "class SequentialSampler(BaseSampler):\n",
    "\n",
    "    def query(self, n_candidates=10):\n",
    "        ids = getUnlabelledIds(self.db, split=\"train\")\n",
    "        return sorted(ids, key=int)[0:n_candidates]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> prepare the directories for data exchange between pixano and annotation tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# TEMPORARY SOLUTION\n",
    "def create_dir(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except:\n",
    "        print(f'Dir {path} exists already')\n",
    "    return path\n",
    "# here define the paths of exchanging data between pixano and the customLearner\n",
    "temp_data_exchange_dir = create_dir(os.path.join(ROOTDIR,\"temp_data\"))                # define a directory for exchanging data\n",
    "output_queDir=create_dir(os.path.join(temp_data_exchange_dir,\"output_queries\"))       # [out] query strategy results\n",
    "output_accDir=create_dir(os.path.join(temp_data_exchange_dir,\"output_accuracy\"))      # [out] accuracy results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> define the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customTrainer():\n",
    "\n",
    "    weights_dir=\"_weights\"\n",
    "    # batch_size = 16\n",
    "    learning_rate=0.001\n",
    "    n_epoch=100\n",
    "    model=\"mlp\" \n",
    "    \n",
    "    mode='train'\n",
    "    customLearnerCondaEnv = \"customLearner3\"\n",
    "\n",
    "    #in this trainer we train only on last round\n",
    "    def __init__(self, db, model, validation_data, **kwargs):\n",
    "        self.db = db\n",
    "        self.validation_data = validation_data # ---------------------------> remove later\n",
    "        self.initial_epoch = 0\n",
    "\n",
    "        # sets new values to any default arguments passed during construction    \n",
    "        for key, value in kwargs.items():\n",
    "            if hasattr(self, key):\n",
    "                self.set_parameter(key,value)\n",
    "    \n",
    "    def set_parameter(self,key,value):\n",
    "        # change member variable members. Public method that can be used outside the scope of the scope\n",
    "        if hasattr(self, key):\n",
    "            setattr(self, key, value)\n",
    "        else:\n",
    "            print(f'Argument {key} does not exist. Value of {value} does not set any of the member values of the customTrainer class')\n",
    "\n",
    "    # training on subset data\n",
    "    def train(self, epochs, batch_size):\n",
    "\n",
    "        curRound = getLastRound(self.db)\n",
    "        # csvAcc=os.path.join(output_accDir,\"accuracy\"+str(curRound)+\".csv\")\n",
    "        csvAcc=os.path.join(output_accDir,\"accuracy.csv\")\n",
    "\n",
    "        arguments = f\"--data_name {DATASET_NAME} --mode {self.mode} --mode train --train_out {csvAcc} --data_dir {import_dir} --n_query {labels_per_round} --learning_rate {learning_rate} --n_epoch {max_epochs_per_round} --model {model_name} --strategy {strategy} --alpha_opt\"\n",
    "        subprocess.run(f\"\"\"source ~/miniconda3/etc/profile.d/conda.sh\n",
    "            conda activate {self.customLearnerCondaEnv} \n",
    "            python alpha_mix_active_learning/_main.py {arguments}\"\"\", #{customLearner_ROOTDIR}/customLearner_main_3\n",
    "            shell=True, executable='/bin/bash', check=True)\n",
    "\n",
    "        trainOut = pd.read_csv(csvAcc,index_col=0)\n",
    "        return {\n",
    "            \"score\": 100 * trainOut.loc[\"round_\"+str(curRound),\"accuracy\"]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CERTH - Custom Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here define the implementation for the new sampler\n",
    "class customSampler(BaseSampler):\n",
    "    \n",
    "    #add all other dependencies define in https://docs.google.com/document/d/1NlArhWYjePzB43sR4HCUc_4xBU73Up9OI24hIyPx0zY/edit\n",
    "\n",
    "    # for now only the vital ones\n",
    "    output_dir=\"_output\"\n",
    "    log_directory=\"_logs\"\n",
    "    n_init_lb=100\n",
    "    n_query=100 \n",
    "    alpha_opt=True\n",
    "    mode = \"query\"\n",
    "    stategy = \"AlphaMixSampling\" #EntropySampling #RandomSampling\n",
    "    model = \"mlp\"\n",
    "    customLearnerCondaEnv = \"customLearner3\"\n",
    "\n",
    "    def __init__(self, dataset, **kwargs):\n",
    "        super().__init__(dataset)\n",
    "\n",
    "        # sets new values to any default arguments passed during construction    \n",
    "        for key, value in kwargs.items():\n",
    "            if hasattr(self, key):\n",
    "                self.set_parameter(key,value)\n",
    "\n",
    "    def set_parameter(self,key,value):\n",
    "        # change member variable members. Public method that can be used outside the scope of the scope\n",
    "        if hasattr(self, key):\n",
    "            setattr(self, key, value)\n",
    "        else:\n",
    "            print(f'Argument {key} does not exist. Value of {value} does not set any of the member values of the customSampler class')\n",
    "\n",
    "    def query(self, discard_n_candidates=10):\n",
    "        # under active development\n",
    "        round = getLastRound(self.db)\n",
    "\n",
    "        # if (round == -1):                                                   # random sampling when labels are absent\n",
    "        #     ids = getLabelledIds(self.db, round)\n",
    "        #     return random.sample(ids, labels_per_round)\n",
    "        # elif (round >= 0):\n",
    "        curRound = getLastRound(self.db)\n",
    "\n",
    "        csvQue=os.path.join(output_queDir,\"queries_\"+str(curRound)+\".csv\")\n",
    "\n",
    "        arguments = f\"--data_name {DATASET_NAME} --data_dir {import_dir} --mode {self.mode} --query_out {csvQue} --n_query {labels_per_round} --model {model_name} --strategy {strategy} --alpha_opt\"\n",
    "        subprocess.run(f\"\"\"source ~/miniconda3/etc/profile.d/conda.sh\n",
    "                    conda activate {self.customLearnerCondaEnv} \n",
    "                    python alpha_mix_active_learning/_main.py {arguments}\"\"\",\n",
    "                    shell=True, executable='/bin/bash', check=True)\n",
    "        \n",
    "        queryOut = pd.read_csv(csvQue,index_col=0)\n",
    "        \n",
    "        return queryOut[\"query_results\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling Interface Objects\n",
    "\n",
    "Human labeling with Pixano Annotator is built-in, here we specify an Auto Annotator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoAnnotator(BaseAnnotator):\n",
    "    # custom annotation function\n",
    "    # as we have ground truth for MNIST, we can autofill\n",
    "    def annotate(self, round):\n",
    "        candidates = getTaggedIds(self.db, round)\n",
    "        db_tbl = mnist_db.open_table(\"db\")\n",
    "        custom_update(db_tbl, f\"id in ({ddb_str(candidates)})\", 'label', [str(Y_train[id_to_idx(candidate)]) for candidate in sorted(candidates, key=natural_key)])\n",
    "        print(f\"AutoAnnotator: round {round} annotated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanceTable(db)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_db.open_table(\"db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orchestrator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on all data, don't reset weights before each training round (it may overfit on first rounds data)\n",
    "# myTrainer = SimpleTrainer(mnist_db, model, (x_test, y_test))\n",
    "\n",
    "# train on all data, reset weights before each training round\n",
    "#myTrainer = SimpleTrainer(mnist_db, model, (x_test, y_test), avoid_overfit=True) \n",
    "\n",
    "# train on candidates data (without resetting weights obviously)\n",
    "# myTrainer = IncrementalTrainer(mnist_db, model, (x_test, y_test))\n",
    "myTrainer = customTrainer(mnist_db, model, (x_test, y_test))\n",
    "\n",
    "# randomSampler = RandomSampler(mnist_db)\n",
    "randomSampler = customSampler(mnist_db,n_query=200, irrelevant=5)\n",
    "\n",
    "autofillAnnotator = AutoAnnotator(mnist_db)\n",
    "\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################################### INTERNAL GPU CHECK ######################################################\n",
      "\n",
      "\n",
      "is_available  True\n",
      "device_count  1\n",
      "current device  0\n",
      "cuda.device  <torch.cuda.device object at 0x7fa81024ff70>\n",
      "device name  NVIDIA GeForce RTX 3090\n",
      "\n",
      "\n",
      "################################################################################################################################\n",
      "\n",
      "\n",
      "Namespace(mode='query', data_name='MNIST_pixano_v8', n_label=10, data_dir='/home/melissap/_pixano_datasets_/MNIST_pixano_v7', train_out=None, query_out='/home/melissap/Desktop/LAGO_43integrationDemo/pixano/temp_data/output_queries/queries_-1.csv', log_dir='_logs', save_checkpoints=False, save_images=False, print_to_file=False, seeds=[1, 10, 100, 1000, 10000], init_lb_method='general_random', n_query=100, query_growth_ratio=1, strategy='AlphaMixSampling', n_drop=5, eps=0.05, max_iter=50, alpha_cap=0.03125, alpha_opt=True, alpha_closed_form_approx=True, alpha_learning_rate=0.1, alpha_clf_coef=1.0, alpha_l2_coef=0.01, alpha_learning_iters=5, alpha_learn_batch_size=1000000)\n",
      "Round 0 tagged\n",
      "115 candidates on round 0\n",
      "AutoAnnotator: round 0 annotated.\n",
      "\n",
      "\n",
      "###################################################### INTERNAL GPU CHECK ######################################################\n",
      "\n",
      "\n",
      "is_available  True\n",
      "device_count  1\n",
      "current device  0\n",
      "cuda.device  <torch.cuda.device object at 0x7f1fe6f53d90>\n",
      "device name  NVIDIA GeForce RTX 3090\n",
      "\n",
      "\n",
      "################################################################################################################################\n",
      "\n",
      "\n",
      "Namespace(mode='train', data_name='MNIST_pixano_v8', n_label=10, data_dir='/home/melissap/_pixano_datasets_/MNIST_pixano_v7', train_out='/home/melissap/Desktop/LAGO_43integrationDemo/pixano/temp_data/output_accuracy/accuracy.csv', query_out='path to the file', log_dir='_logs', save_checkpoints=False, save_images=False, print_to_file=False, seeds=[1, 10, 100, 1000, 10000], init_lb_method='general_random', n_query=100, query_growth_ratio=1, strategy='AlphaMixSampling', n_drop=5, eps=0.05, max_iter=50, alpha_cap=0.03125, alpha_opt=True, alpha_closed_form_approx=True, alpha_learning_rate=0.1, alpha_clf_coef=1.0, alpha_l2_coef=0.01, alpha_learning_iters=5, alpha_learn_batch_size=1000000)\n",
      "number of labeled pool: 500\n",
      "number of unlabeled pool: 59500\n",
      "number of validation pool: 0\n",
      "number of testing pool: 77\n",
      "Using cuda device.\n",
      "MNIST_pixano_v8\n",
      "SEED 1\n",
      "AlphaMixSampling\n",
      "Adam optimizer...\n",
      "Training started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [00:28<01:21,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached max accuracy at epoch 26 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [00:29<01:25,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0\n",
      "testing accuracy 0.07792207792207792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 7.79220779220779}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_learner = Learner(\n",
    "    db=mnist_db,\n",
    "    trainer=myTrainer,\n",
    "    sampler=randomSampler,\n",
    "    custom_annotator=autofillAnnotator,\n",
    "    new_al=True,\n",
    "    verbose=0\n",
    ")\n",
    "candidates = init_learner.query(round, labels_per_round)\n",
    "init_learner.annotate(round)\n",
    "init_learner.train(round, epochs=epochs)\n",
    "\n",
    "# round += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################################### INTERNAL GPU CHECK ######################################################\n",
      "\n",
      "\n",
      "is_available  True\n",
      "device_count  1\n",
      "current device  0\n",
      "cuda.device  <torch.cuda.device object at 0x7fb73eb67e50>\n",
      "device name  NVIDIA GeForce RTX 3090\n",
      "\n",
      "\n",
      "################################################################################################################################\n",
      "\n",
      "\n",
      "Namespace(mode='query', data_name='MNIST_pixano_v8', n_label=10, data_dir='/home/melissap/_pixano_datasets_/MNIST_pixano_v7', train_out=None, query_out='/home/melissap/Desktop/LAGO_43integrationDemo/pixano/temp_data/output_queries/queries_0.csv', log_dir='_logs', save_checkpoints=False, save_images=False, print_to_file=False, seeds=[1, 10, 100, 1000, 10000], init_lb_method='general_random', n_query=100, query_growth_ratio=1, strategy='AlphaMixSampling', n_drop=5, eps=0.05, max_iter=50, alpha_cap=0.03125, alpha_opt=True, alpha_closed_form_approx=True, alpha_learning_rate=0.1, alpha_clf_coef=1.0, alpha_l2_coef=0.01, alpha_learning_iters=5, alpha_learn_batch_size=1000000)\n",
      "number of labeled pool: 500\n",
      "number of unlabeled pool: 59500\n",
      "number of validation pool: 0\n",
      "number of testing pool: 77\n",
      "Using cuda device.\n",
      "Loading weights mlp_MNIST_pixano_v8_AlphaMixSampling_0_weights.pth\n",
      "MNIST_pixano_v8\n",
      "SEED 1\n",
      "AlphaMixSampling\n",
      "Round 0\n",
      "query budget: 100\n",
      "With alpha_cap set to 0.031250, number of inconsistencies: 2043\n",
      "Number of inconsistencies: 2043\n",
      "alpha_mean_mean: 1.000000\n",
      "alpha_std_mean: 0.000000\n",
      "alpha_mean_std 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/melissap/miniconda3/envs/customLearner3/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples that are misclassified and selected: 100 (100.00%)\n",
      "Log Determinant of the Gram Matrix: 409.295441\n",
      "Signed Log Determinant of the Gram Matrix: 409.295441\n",
      "Confidence: 0.324890\n",
      "Margin: 0.007934\n",
      "Predicted Entropy: 2.264852\n",
      "GT Entropy: nan\n",
      "Border Entropy: 3.553058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/melissap/miniconda3/envs/customLearner3/lib/python3.10/site-packages/scipy/stats/_entropy.py:133: RuntimeWarning: invalid value encountered in divide\n",
      "  pk = 1.0*pk / np.sum(pk, axis=axis, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0 tagged\n"
     ]
    }
   ],
   "source": [
    "candidates = init_learner.query(round, labels_per_round)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add some auto-annotation rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################################### INTERNAL GPU CHECK ######################################################\n",
      "\n",
      "\n",
      "is_available  True\n",
      "device_count  1\n",
      "current device  0\n",
      "cuda.device  <torch.cuda.device object at 0x7fbe3ffb4550>\n",
      "device name  NVIDIA GeForce RTX 3090\n",
      "\n",
      "\n",
      "################################################################################################################################\n",
      "\n",
      "\n",
      "Namespace(mode='query', data_name='MNIST_pixano_v7', n_label=10, data_dir='/home/melissap/_pixano_datasets_/MNIST_pixano_v7', train_out=None, query_out='/home/melissap/Desktop/LAGO_43integrationDemo/pixano/temp_data/output_queries/queries_0.csv', log_dir='_logs', save_checkpoints=False, save_images=False, print_to_file=False, seeds=[1, 10, 100, 1000, 10000], init_lb_method='general_random', n_query=100, query_growth_ratio=1, strategy='AlphaMixSampling', n_drop=5, eps=0.05, max_iter=50, alpha_cap=0.03125, alpha_opt=True, alpha_closed_form_approx=True, alpha_learning_rate=0.1, alpha_clf_coef=1.0, alpha_l2_coef=0.01, alpha_learning_iters=5, alpha_learn_batch_size=1000000)\n",
      "number of labeled pool: 100\n",
      "number of unlabeled pool: 59900\n",
      "number of validation pool: 0\n",
      "number of testing pool: 10\n",
      "Using cuda device.\n",
      "Loading weights mlp_MNIST_pixano_v7_AlphaMixSampling_0_weights.pth\n",
      "MNIST_pixano_v7\n",
      "SEED 1\n",
      "AlphaMixSampling\n",
      "Round 0\n",
      "query budget: 100\n",
      "With alpha_cap set to 0.031250, number of inconsistencies: 1364\n",
      "Number of inconsistencies: 1364\n",
      "alpha_mean_mean: 1.000000\n",
      "alpha_std_mean: 0.000000\n",
      "alpha_mean_std 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/melissap/miniconda3/envs/customLearner3/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples that are misclassified and selected: 100 (100.00%)\n",
      "Log Determinant of the Gram Matrix: 310.990723\n",
      "Signed Log Determinant of the Gram Matrix: 310.990723\n",
      "Confidence: 0.302082\n",
      "Margin: 0.004412\n",
      "Predicted Entropy: 2.174998\n",
      "GT Entropy: nan\n",
      "Border Entropy: 3.317727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/melissap/miniconda3/envs/customLearner3/lib/python3.10/site-packages/scipy/stats/_entropy.py:133: RuntimeWarning: invalid value encountered in divide\n",
      "  pk = 1.0*pk / np.sum(pk, axis=axis, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0 tagged\n",
      "223 candidates on round 0\n",
      "AutoAnnotator: round 0 annotated.\n",
      "\n",
      "\n",
      "###################################################### INTERNAL GPU CHECK ######################################################\n",
      "\n",
      "\n",
      "is_available  True\n",
      "device_count  1\n",
      "current device  0\n",
      "cuda.device  <torch.cuda.device object at 0x7f8fa8594520>\n",
      "device name  NVIDIA GeForce RTX 3090\n",
      "\n",
      "\n",
      "################################################################################################################################\n",
      "\n",
      "\n",
      "Namespace(mode='train', data_name='MNIST_pixano_v7', n_label=10, data_dir='/home/melissap/_pixano_datasets_/MNIST_pixano_v7', train_out='/home/melissap/Desktop/LAGO_43integrationDemo/pixano/temp_data/output_accuracy/accuracy.csv', query_out='path to the file', log_dir='_logs', save_checkpoints=False, save_images=False, print_to_file=False, seeds=[1, 10, 100, 1000, 10000], init_lb_method='general_random', n_query=100, query_growth_ratio=1, strategy='AlphaMixSampling', n_drop=5, eps=0.05, max_iter=50, alpha_cap=0.03125, alpha_opt=True, alpha_closed_form_approx=True, alpha_learning_rate=0.1, alpha_clf_coef=1.0, alpha_l2_coef=0.01, alpha_learning_iters=5, alpha_learn_batch_size=1000000)\n",
      "number of labeled pool: 200\n",
      "number of unlabeled pool: 59800\n",
      "number of validation pool: 0\n",
      "number of testing pool: 23\n",
      "Using cuda device.\n",
      "MNIST_pixano_v7\n",
      "SEED 1\n",
      "AlphaMixSampling\n",
      "Adam optimizer...\n",
      "Training started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [00:33<01:02,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached max accuracy at epoch 34 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [00:34<01:07,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0\n",
      "testing accuracy 0.0\n",
      "\n",
      "\n",
      "###################################################### INTERNAL GPU CHECK ######################################################\n",
      "\n",
      "\n",
      "is_available  True\n",
      "device_count  1\n",
      "current device  0\n",
      "cuda.device  <torch.cuda.device object at 0x7fa02817c5e0>\n",
      "device name  NVIDIA GeForce RTX 3090\n",
      "\n",
      "\n",
      "################################################################################################################################\n",
      "\n",
      "\n",
      "Namespace(mode='query', data_name='MNIST_pixano_v7', n_label=10, data_dir='/home/melissap/_pixano_datasets_/MNIST_pixano_v7', train_out=None, query_out='/home/melissap/Desktop/LAGO_43integrationDemo/pixano/temp_data/output_queries/queries_0.csv', log_dir='_logs', save_checkpoints=False, save_images=False, print_to_file=False, seeds=[1, 10, 100, 1000, 10000], init_lb_method='general_random', n_query=100, query_growth_ratio=1, strategy='AlphaMixSampling', n_drop=5, eps=0.05, max_iter=50, alpha_cap=0.03125, alpha_opt=True, alpha_closed_form_approx=True, alpha_learning_rate=0.1, alpha_clf_coef=1.0, alpha_l2_coef=0.01, alpha_learning_iters=5, alpha_learn_batch_size=1000000)\n",
      "number of labeled pool: 200\n",
      "number of unlabeled pool: 59800\n",
      "number of validation pool: 0\n",
      "number of testing pool: 23\n",
      "Using cuda device.\n",
      "Loading weights mlp_MNIST_pixano_v7_AlphaMixSampling_0_weights.pth\n",
      "MNIST_pixano_v7\n",
      "SEED 1\n",
      "AlphaMixSampling\n",
      "Round 0\n",
      "query budget: 100\n",
      "With alpha_cap set to 0.031250, number of inconsistencies: 1735\n",
      "Number of inconsistencies: 1735\n",
      "alpha_mean_mean: 1.000000\n",
      "alpha_std_mean: 0.000000\n",
      "alpha_mean_std 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/melissap/miniconda3/envs/customLearner3/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples that are misclassified and selected: 100 (100.00%)\n",
      "Log Determinant of the Gram Matrix: 364.347290\n",
      "Signed Log Determinant of the Gram Matrix: 364.347290\n",
      "Confidence: 0.327119\n",
      "Margin: 0.006281\n",
      "Predicted Entropy: 2.259030\n",
      "GT Entropy: nan\n",
      "Border Entropy: 3.518425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/melissap/miniconda3/envs/customLearner3/lib/python3.10/site-packages/scipy/stats/_entropy.py:133: RuntimeWarning: invalid value encountered in divide\n",
      "  pk = 1.0*pk / np.sum(pk, axis=axis, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 tagged\n",
      "122 candidates on round 1\n",
      "AutoAnnotator: round 1 annotated.\n",
      "\n",
      "\n",
      "###################################################### INTERNAL GPU CHECK ######################################################\n",
      "\n",
      "\n",
      "is_available  True\n",
      "device_count  1\n",
      "current device  0\n",
      "cuda.device  <torch.cuda.device object at 0x7fa9baba0610>\n",
      "device name  NVIDIA GeForce RTX 3090\n",
      "\n",
      "\n",
      "################################################################################################################################\n",
      "\n",
      "\n",
      "Namespace(mode='train', data_name='MNIST_pixano_v7', n_label=10, data_dir='/home/melissap/_pixano_datasets_/MNIST_pixano_v7', train_out='/home/melissap/Desktop/LAGO_43integrationDemo/pixano/temp_data/output_accuracy/accuracy.csv', query_out='path to the file', log_dir='_logs', save_checkpoints=False, save_images=False, print_to_file=False, seeds=[1, 10, 100, 1000, 10000], init_lb_method='general_random', n_query=100, query_growth_ratio=1, strategy='AlphaMixSampling', n_drop=5, eps=0.05, max_iter=50, alpha_cap=0.03125, alpha_opt=True, alpha_closed_form_approx=True, alpha_learning_rate=0.1, alpha_clf_coef=1.0, alpha_l2_coef=0.01, alpha_learning_iters=5, alpha_learn_batch_size=1000000)\n",
      "number of labeled pool: 300\n",
      "number of unlabeled pool: 59700\n",
      "number of validation pool: 0\n",
      "number of testing pool: 45\n",
      "Using cuda device.\n",
      "MNIST_pixano_v7\n",
      "SEED 1\n",
      "AlphaMixSampling\n",
      "Adam optimizer...\n",
      "Loading weights mlp_MNIST_pixano_v7_AlphaMixSampling_0_weights.pth\n",
      " Print the weights of the model to ensure that weights are loaded \n",
      "Training started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [00:13<01:28,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached max accuracy at epoch 12 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [00:13<01:42,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0\n",
      "testing accuracy 0.06666666666666667\n",
      "\n",
      "\n",
      "###################################################### INTERNAL GPU CHECK ######################################################\n",
      "\n",
      "\n",
      "is_available  True\n",
      "device_count  1\n",
      "current device  0\n",
      "cuda.device  <torch.cuda.device object at 0x7f8a501cc610>\n",
      "device name  NVIDIA GeForce RTX 3090\n",
      "\n",
      "\n",
      "################################################################################################################################\n",
      "\n",
      "\n",
      "Namespace(mode='query', data_name='MNIST_pixano_v7', n_label=10, data_dir='/home/melissap/_pixano_datasets_/MNIST_pixano_v7', train_out=None, query_out='/home/melissap/Desktop/LAGO_43integrationDemo/pixano/temp_data/output_queries/queries_1.csv', log_dir='_logs', save_checkpoints=False, save_images=False, print_to_file=False, seeds=[1, 10, 100, 1000, 10000], init_lb_method='general_random', n_query=100, query_growth_ratio=1, strategy='AlphaMixSampling', n_drop=5, eps=0.05, max_iter=50, alpha_cap=0.03125, alpha_opt=True, alpha_closed_form_approx=True, alpha_learning_rate=0.1, alpha_clf_coef=1.0, alpha_l2_coef=0.01, alpha_learning_iters=5, alpha_learn_batch_size=1000000)\n",
      "number of labeled pool: 300\n",
      "number of unlabeled pool: 59700\n",
      "number of validation pool: 0\n",
      "number of testing pool: 45\n",
      "Using cuda device.\n",
      "Loading weights mlp_MNIST_pixano_v7_AlphaMixSampling_1_weights.pth\n",
      "MNIST_pixano_v7\n",
      "SEED 1\n",
      "AlphaMixSampling\n",
      "Round 1\n",
      "query budget: 100\n",
      "With alpha_cap set to 0.031250, number of inconsistencies: 1846\n",
      "Number of inconsistencies: 1846\n",
      "alpha_mean_mean: 1.000000\n",
      "alpha_std_mean: 0.000000\n",
      "alpha_mean_std 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/melissap/miniconda3/envs/customLearner3/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples that are misclassified and selected: 100 (100.00%)\n",
      "Log Determinant of the Gram Matrix: 386.348907\n",
      "Signed Log Determinant of the Gram Matrix: 386.348907\n",
      "Confidence: 0.314974\n",
      "Margin: 0.006477\n",
      "Predicted Entropy: 2.227732\n",
      "GT Entropy: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/melissap/miniconda3/envs/customLearner3/lib/python3.10/site-packages/scipy/stats/_entropy.py:133: RuntimeWarning: invalid value encountered in divide\n",
      "  pk = 1.0*pk / np.sum(pk, axis=axis, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Border Entropy: 3.510777\n",
      "Round 2 tagged\n",
      "117 candidates on round 2\n",
      "AutoAnnotator: round 2 annotated.\n",
      "\n",
      "\n",
      "###################################################### INTERNAL GPU CHECK ######################################################\n",
      "\n",
      "\n",
      "is_available  True\n",
      "device_count  1\n",
      "current device  0\n",
      "cuda.device  <torch.cuda.device object at 0x7fc3def74580>\n",
      "device name  NVIDIA GeForce RTX 3090\n",
      "\n",
      "\n",
      "################################################################################################################################\n",
      "\n",
      "\n",
      "Namespace(mode='train', data_name='MNIST_pixano_v7', n_label=10, data_dir='/home/melissap/_pixano_datasets_/MNIST_pixano_v7', train_out='/home/melissap/Desktop/LAGO_43integrationDemo/pixano/temp_data/output_accuracy/accuracy.csv', query_out='path to the file', log_dir='_logs', save_checkpoints=False, save_images=False, print_to_file=False, seeds=[1, 10, 100, 1000, 10000], init_lb_method='general_random', n_query=100, query_growth_ratio=1, strategy='AlphaMixSampling', n_drop=5, eps=0.05, max_iter=50, alpha_cap=0.03125, alpha_opt=True, alpha_closed_form_approx=True, alpha_learning_rate=0.1, alpha_clf_coef=1.0, alpha_l2_coef=0.01, alpha_learning_iters=5, alpha_learn_batch_size=1000000)\n",
      "number of labeled pool: 400\n",
      "number of unlabeled pool: 59600\n",
      "number of validation pool: 0\n",
      "number of testing pool: 62\n",
      "Using cuda device.\n",
      "MNIST_pixano_v7\n",
      "SEED 1\n",
      "AlphaMixSampling\n",
      "Adam optimizer...\n",
      "Loading weights mlp_MNIST_pixano_v7_AlphaMixSampling_1_weights.pth\n",
      " Print the weights of the model to ensure that weights are loaded \n",
      "Training started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [00:17<01:34,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached max accuracy at epoch 16 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [00:18<01:37,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0\n",
      "testing accuracy 0.08064516129032258\n"
     ]
    }
   ],
   "source": [
    "auto_rounds = 3\n",
    "round_size = 20\n",
    "for round in range(round, round+auto_rounds):\n",
    "    candidates = init_learner.query(round, round_size)\n",
    "    init_learner.annotate(round)\n",
    "    init_learner.train(round, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Active Learning - Human annotation with Pixano Annotator\n",
    "\n",
    "Here we use a different Learner for human annotation. Trainer Object use the same model so we keep training it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################################### INTERNAL GPU CHECK ######################################################\n",
      "\n",
      "\n",
      "is_available  True\n",
      "device_count  1\n",
      "current device  0\n",
      "cuda.device  <torch.cuda.device object at 0x7f5cfd37fe20>\n",
      "device name  NVIDIA GeForce RTX 3090\n",
      "\n",
      "\n",
      "################################################################################################################################\n",
      "\n",
      "\n",
      "Namespace(mode='query', data_name='MNIST_pixano_v8', n_label=10, data_dir='/home/melissap/_pixano_datasets_/MNIST_pixano_v7', train_out=None, query_out='/home/melissap/Desktop/LAGO_43integrationDemo/pixano/temp_data/output_queries/queries_0.csv', log_dir='_logs', save_checkpoints=False, save_images=False, print_to_file=False, seeds=[1, 10, 100, 1000, 10000], init_lb_method='general_random', n_query=100, query_growth_ratio=1, strategy='AlphaMixSampling', n_drop=5, eps=0.05, max_iter=50, alpha_cap=0.03125, alpha_opt=True, alpha_closed_form_approx=True, alpha_learning_rate=0.1, alpha_clf_coef=1.0, alpha_l2_coef=0.01, alpha_learning_iters=5, alpha_learn_batch_size=1000000)\n",
      "number of labeled pool: 500\n",
      "number of unlabeled pool: 59500\n",
      "number of validation pool: 0\n",
      "number of testing pool: 77\n",
      "Using cuda device.\n",
      "Loading weights mlp_MNIST_pixano_v8_AlphaMixSampling_0_weights.pth\n",
      "MNIST_pixano_v8\n",
      "SEED 1\n",
      "AlphaMixSampling\n",
      "Round 0\n",
      "query budget: 100\n",
      "With alpha_cap set to 0.031250, number of inconsistencies: 2043\n",
      "Number of inconsistencies: 2043\n",
      "alpha_mean_mean: 1.000000\n",
      "alpha_std_mean: 0.000000\n",
      "alpha_mean_std 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/melissap/miniconda3/envs/customLearner3/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples that are misclassified and selected: 100 (100.00%)\n",
      "Log Determinant of the Gram Matrix: 409.295441\n",
      "Signed Log Determinant of the Gram Matrix: 409.295441\n",
      "Confidence: 0.324890\n",
      "Margin: 0.007934\n",
      "Predicted Entropy: 2.264852\n",
      "GT Entropy: nan\n",
      "Border Entropy: 3.553058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/melissap/miniconda3/envs/customLearner3/lib/python3.10/site-packages/scipy/stats/_entropy.py:133: RuntimeWarning: invalid value encountered in divide\n",
      "  pk = 1.0*pk / np.sum(pk, axis=axis, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 2 tagged\n",
      "115 candidates on round 2\n",
      "115 items to annotate on round 2: ['23776.jpeg', '24055.jpeg', '24297.jpeg', '24548.jpeg', '41605.jpeg', '41922.jpeg', '58321.jpeg', '58366.jpeg', '43076.jpeg', '59850.jpeg', '9962.jpeg', '26238.jpeg', '42208.jpeg', '42603.jpeg', '42867.jpeg', '44517.jpeg', '44641.jpeg', '44821.jpeg', '426.jpeg', '649.jpeg', '7691.jpeg', '7822.jpeg', '7863.jpeg', '7894.jpeg', '8007.jpeg', '10283.jpeg', '10482.jpeg', '10621.jpeg', '10908.jpeg', '11090.jpeg', '12398.jpeg', '12997.jpeg', '13126.jpeg', '28441.jpeg', '11526.jpeg', '11868.jpeg', '12233.jpeg', '45293.jpeg', '45300.jpeg', '45501.jpeg', '1884.jpeg', '13405.jpeg', '30042.jpeg', '46149.jpeg', '47099.jpeg', '3037.jpeg', '30807.jpeg', '31451.jpeg', '47107.jpeg', '47837.jpeg', '3945.jpeg', '15708.jpeg', '15713.jpeg', '15977.jpeg', '16297.jpeg', '18838.jpeg', '19371.jpeg', '35011.jpeg', '35279.jpeg', '1884.jpeg', '18285.jpeg', '18286.jpeg', '34065.jpeg', '34447.jpeg', '34548.jpeg', '7090.jpeg', '426.jpeg', '649.jpeg', '16512.jpeg', '17180.jpeg', '31765.jpeg', '32708.jpeg', '48315.jpeg', '5287.jpeg', '5490.jpeg', '3037.jpeg', '5287.jpeg', '5490.jpeg', '20507.jpeg', '37695.jpeg', '7691.jpeg', '7822.jpeg', '7863.jpeg', '7894.jpeg', '8007.jpeg', '8356.jpeg', '21794.jpeg', '22350.jpeg', '22408.jpeg', '38771.jpeg', '38819.jpeg', '54733.jpeg', '55027.jpeg', '7090.jpeg', '22600.jpeg', '23027.jpeg', '39362.jpeg', '9962.jpeg', '3945.jpeg', '20208.jpeg', '36432.jpeg', '36589.jpeg', '52301.jpeg', '52413.jpeg', '52812.jpeg', '33381.jpeg', '50004.jpeg', '51409.jpeg', '55312.jpeg', '56073.jpeg', '56233.jpeg', '8356.jpeg', '24920.jpeg', '25333.jpeg', '56522.jpeg']\n",
      "Interrupted, current round has been canceled, and round labels erased\n"
     ]
    }
   ],
   "source": [
    "pix_rounds = 3\n",
    "\n",
    "learner_pix = Learner(\n",
    "    db=mnist_db,\n",
    "    trainer=myTrainer,\n",
    "    sampler=randomSampler\n",
    ")\n",
    "for round in range(round + 1, pix_rounds + round + 1):\n",
    "    candidates = learner_pix.query(round , \"pix_round_size - defined_within_class\")\n",
    "    # if aborted, we must untag the current round \n",
    "    try:\n",
    "        learner_pix.annotate(round)\n",
    "    except KeyboardInterrupt:\n",
    "        learner_pix.untagRound(round)\n",
    "        round = round - 1\n",
    "        print(\"Interrupted, current round has been canceled, and round labels erased\")\n",
    "        break\n",
    "    result = learner_pix.train(round, epochs=epochs)\n",
    "    print(\"result\", result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 ('pixano')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6604ca948f4575fb1939f96f2cd7df5de428f245d6855ef61050d788c6a2a026"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
