{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Learning with Pixano - MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> initialize vital variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration variables\n",
    "DATASET_NAME=\"MNIST_pixano_v7\"\n",
    "customLearnerCondaEnv=\"customLearner3\"\n",
    "\n",
    "# variables that could be defined \n",
    "labels_per_round=100\n",
    "round = 0 # current round\n",
    "learning_rate=0.001\n",
    "max_epochs_per_round=100\n",
    "model_name=\"mlp\" \n",
    "strategy=\"AlphaMixSampling\" #EntropySampling #RandomSampling\n",
    "alpha_opt=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> import ROOT dir to import pixano root module , which is the pixano directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/melissap/Desktop/LAGO_43integrationDemo/pixano/ActiveLearning/certh_integration/231031_mnist\n",
      "/home/melissap/Desktop/LAGO_43integrationDemo/pixano/ActiveLearning/certh_integration\n",
      "/home/melissap/Desktop/LAGO_43integrationDemo/pixano/ActiveLearning\n",
      "Inserting parent dir :  /home/melissap/Desktop/LAGO_43integrationDemo/pixano\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "def insertRootDir(ROOTDIR='pixano'):\n",
    "    pardir=os.path.dirname(os.path.realpath('__file__'))\n",
    "\n",
    "    while(os.path.basename(pardir)!=ROOTDIR):\n",
    "\n",
    "        print(pardir)\n",
    "        pardir=os.path.dirname(pardir)\n",
    "        # print(os.path.basename(pardir))\n",
    "    print(\"Inserting parent dir : \",pardir)\n",
    "    sys.path.insert(0,pardir)\n",
    "    return pardir\n",
    "\n",
    "ROOTDIR = insertRootDir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pixano.data import ImageImporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "library_dir=Path('/home/melissap/_pixano_datasets_') # directory where we have install the pixano formatted dataset\n",
    "import_dir = library_dir / DATASET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' NOT REQUIRED  +  BUGGED\\n\\n# TAKEN FROM THE MNIST.ipynb notebook\\n# output path for lance database\\nDB_PATH = library_dir / \"_launce_datasets_/MNIST\"\\n# input image path\\nIMG_PATH = import_dir / \"media\"\\n# Note: images have been generated by MNIST (v1) notebook, and moved here\\n# TODO add a cell to generate image from mnist (from keras.datasets import mnist)\\n\\nmnist_importer = ImageImporter(\"MNIST\", \"MNIST dataset for AL\", [\"train\", \"test\"])\\nmnist_importer.import_dataset(\\n    input_dirs={ \"image\": IMG_PATH },\\n    import_dir=DB_PATH,\\n    portable=True\\n)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" NOT REQUIRED  +  BUGGED\n",
    "\n",
    "# TAKEN FROM THE MNIST.ipynb notebook\n",
    "# output path for lance database\n",
    "DB_PATH = library_dir / \"_launce_datasets_/MNIST\"\n",
    "# input image path\n",
    "IMG_PATH = import_dir / \"media\"\n",
    "# Note: images have been generated by MNIST (v1) notebook, and moved here\n",
    "# TODO add a cell to generate image from mnist (from keras.datasets import mnist)\n",
    "\n",
    "mnist_importer = ImageImporter(\"MNIST\", \"MNIST dataset for AL\", [\"train\", \"test\"])\n",
    "mnist_importer.import_dataset(\n",
    "    input_dirs={ \"image\": IMG_PATH },\n",
    "    import_dir=DB_PATH,\n",
    "    portable=True\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 12:01:09.075183: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import lancedb\n",
    "import pyarrow as pa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.datasets import mnist\n",
    "from ALearner import (\n",
    "    Learner,\n",
    "    BaseAnnotator,\n",
    "    BaseSampler,\n",
    "    BaseTrainer,\n",
    "    getLabels,\n",
    "    getLabelledIds,\n",
    "    getUnlabelledIds,\n",
    "    getTaggedIds,\n",
    "    getLastRound,\n",
    "    ddb_str,\n",
    "    custom_update\n",
    ")\n",
    "from pixano.utils import natural_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function to convert id (format \"<index>.png\") to index\n",
    "def id_to_idx(id: str) -> int:\n",
    "    return int(id.split(\".\")[0])\n",
    "    # return int(id[0:-4])  #remove the last 4 chars (\".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Pixano DB\n",
    "MNIST dataset should have been imported previously (see lance_importers/MNIST.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_db = lancedb.connect(import_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Trainer Object\n",
    "\n",
    "We will get raw x_train, x_test, y_test data directly from MNIST.\n",
    "\n",
    "2 proposed Model Trainer Objects, with same model: SimpleTrainer and IncrementalTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 12:01:10.904216: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "\n",
    "def reshape_Xdata(x):\n",
    "    #flatten images\n",
    "    x = x.reshape(x.shape[0], num_pixels)\n",
    "    #Convert to float\n",
    "    x = x.astype('float32')\n",
    "    #Normalize inputs from [0; 255] to [0; 1]\n",
    "    x = x / 255\n",
    "    return x\n",
    "\n",
    "def reshape_Ydata(y):\n",
    "    #Convert class vectors to binary class matrices (\"one hot encoding\")\n",
    "    ## Doc : https://keras.io/utils/#to_categorical\n",
    "    return keras.utils.to_categorical(y, num_classes=10)  # need to specify num_classes because sampler can miss some classes\n",
    "\n",
    "\n",
    "#x_train = reshape_Xdata(X_train)\n",
    "x_test = reshape_Xdata(X_test)\n",
    "y_train = reshape_Ydata(Y_train)\n",
    "y_test = reshape_Ydata(Y_test)\n",
    "num_classes = y_train.shape[1]\n",
    "\n",
    "def neural_network():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
    "    #model.add(Dropout(.5))\n",
    "    model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = neural_network()\n",
    "\n",
    "\n",
    "class SimpleTrainer(BaseTrainer):\n",
    "    # simple trainer, train on all labeled data\n",
    "    def __init__(self, db, model, validation_data, avoid_overfit=False):\n",
    "        self.init_weights = model.get_weights()\n",
    "        self.avoid_overfit = avoid_overfit\n",
    "        super().__init__(db, model, validation_data)\n",
    "\n",
    "    # training on subset data\n",
    "    def train(self, epochs, batch_size):\n",
    "        # get y data (labels) and ids from db, x data (images) from raw mnist and ids\n",
    "        ids = getLabelledIds(self.db)\n",
    "        labels = getLabels(self.db)\n",
    "        if self.avoid_overfit:\n",
    "            print(\"Reset weights to avoid overfit\")\n",
    "            self.model.set_weights(self.init_weights)\n",
    "        print(f\"Train on {len(ids)} labelled items\")\n",
    "        x_train = reshape_Xdata(np.array([X_train[id_to_idx(id)] for id in ids]))\n",
    "        y_train = reshape_Ydata(np.array(labels))\n",
    "        self.model.fit(x_train, y_train, validation_data=self.validation_data, epochs=epochs, batch_size=batch_size)\n",
    "        scores = model.evaluate(self.validation_data[0], self.validation_data[1])\n",
    "        print(\"Neural network accuracy: %.2f%%\" % (scores[1]*100))\n",
    "        return {\n",
    "            \"score\": scores[1]*100\n",
    "        }\n",
    "\n",
    "class IncrementalTrainer(BaseTrainer):\n",
    "    #in this trainer we train only on last round\n",
    "    def __init__(self, db, model, validation_data):\n",
    "        self.initial_epoch = 0\n",
    "        super().__init__(db, model, validation_data)\n",
    "\n",
    "    # training on subset data\n",
    "    def train(self, epochs, batch_size):\n",
    "        # get y data (labels) and ids from db, x data (images) from raw mnist and ids\n",
    "        round = getLastRound(self.db)\n",
    "        ids = getLabelledIds(self.db, round)\n",
    "        labels = getLabels(self.db, round)\n",
    "        print(f\"Train on {len(ids)} labelled items. initial epoch = {self.initial_epoch}\")\n",
    "        x_train = reshape_Xdata(np.array([X_train[id_to_idx(id)] for id in ids]))\n",
    "        y_train = reshape_Ydata(np.array(labels))\n",
    "        self.model.fit(x_train, y_train, validation_data=self.validation_data, epochs=self.initial_epoch+epochs, batch_size=batch_size, initial_epoch=self.initial_epoch)\n",
    "        scores = model.evaluate(self.validation_data[0], self.validation_data[1])\n",
    "        print(\"Neural network accuracy: %.2f%%\" % (scores[1]*100))\n",
    "        # update initial_epoch for next round\n",
    "        self.initial_epoch += epochs\n",
    "        return {\n",
    "            \"score\": scores[1]*100\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Sampler Object\n",
    "<!-- RandomSampler or SequentialSampler -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: ids (whole dataset, or filtered (here: train only))\n",
    "# output: candidates\n",
    "\n",
    "class RandomSampler(BaseSampler):\n",
    "\n",
    "    def query(self, n_candidates=10):\n",
    "        ids = getUnlabelledIds(self.db, split=\"train\")\n",
    "        return random.sample(ids, n_candidates)\n",
    "\n",
    "class SequentialSampler(BaseSampler):\n",
    "\n",
    "    def query(self, n_candidates=10):\n",
    "        ids = getUnlabelledIds(self.db, split=\"train\")\n",
    "        return sorted(ids, key=int)[0:n_candidates]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> prepare the directories for data exchange between pixano and annotation tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dir /home/melissap/Desktop/LAGO_43integrationDemo/pixano/temp_data exists already\n",
      "Dir /home/melissap/Desktop/LAGO_43integrationDemo/pixano/temp_data/output_queries exists already\n",
      "Dir /home/melissap/Desktop/LAGO_43integrationDemo/pixano/temp_data/output_accuracy exists already\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# TEMPORARY SOLUTION\n",
    "def create_dir(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except:\n",
    "        print(f'Dir {path} exists already')\n",
    "    return path\n",
    "# here define the paths of exchanging data between pixano and the customLearner\n",
    "temp_data_exchange_dir = create_dir(os.path.join(ROOTDIR,\"temp_data\"))                # define a directory for exchanging data\n",
    "output_queDir=create_dir(os.path.join(temp_data_exchange_dir,\"output_queries\"))       # [out] query strategy results\n",
    "output_accDir=create_dir(os.path.join(temp_data_exchange_dir,\"output_accuracy\"))      # [out] accuracy results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> define the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customTrainer():\n",
    "\n",
    "    weights_dir=\"_weights\"\n",
    "    # batch_size = 16\n",
    "    learning_rate=0.001\n",
    "    n_epoch=100\n",
    "    model=\"mlp\" \n",
    "    \n",
    "    mode='train'\n",
    "    customLearnerCondaEnv = \"customLearner3\"\n",
    "\n",
    "    #in this trainer we train only on last round\n",
    "    def __init__(self, db, model, validation_data, **kwargs):\n",
    "        self.db = db\n",
    "        self.validation_data = validation_data # ---------------------------> remove later\n",
    "        self.initial_epoch = 0\n",
    "\n",
    "        # sets new values to any default arguments passed during construction    \n",
    "        for key, value in kwargs.items():\n",
    "            if hasattr(self, key):\n",
    "                self.set_parameter(key,value)\n",
    "    \n",
    "    def set_parameter(self,key,value):\n",
    "        # change member variable members. Public method that can be used outside the scope of the scope\n",
    "        if hasattr(self, key):\n",
    "            setattr(self, key, value)\n",
    "        else:\n",
    "            print(f'Argument {key} does not exist. Value of {value} does not set any of the member values of the customTrainer class')\n",
    "\n",
    "    # training on subset data\n",
    "    def train(self, epochs, batch_size):\n",
    "\n",
    "        curRound = getLastRound(self.db)\n",
    "        # csvAcc=os.path.join(output_accDir,\"accuracy\"+str(curRound)+\".csv\")\n",
    "        csvAcc=os.path.join(output_accDir,\"accuracy.csv\")\n",
    "\n",
    "        arguments = f\"--data_name {DATASET_NAME} --mode {self.mode} --mode train --train_out {csvAcc} --data_dir {import_dir} --n_query {labels_per_round} --learning_rate {learning_rate} --n_epoch {max_epochs_per_round} --model {model_name} --strategy {strategy} --alpha_opt\"\n",
    "        subprocess.run(f\"\"\"source ~/miniconda3/etc/profile.d/conda.sh\n",
    "            conda activate {self.customLearnerCondaEnv} \n",
    "            python alpha_mix_active_learning/_main.py {arguments}\"\"\", #{customLearner_ROOTDIR}/customLearner_main_3\n",
    "            shell=True, executable='/bin/bash', check=True)\n",
    "\n",
    "        trainOut = pd.read_csv(csvAcc,index_col=0)\n",
    "        return {\n",
    "            \"score\": 100 * trainOut.loc[\"round_\"+str(curRound),\"accuracy\"]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CERTH - Custom Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here define the implementation for the new sampler\n",
    "class customSampler(BaseSampler):\n",
    "    \n",
    "    #add all other dependencies define in https://docs.google.com/document/d/1NlArhWYjePzB43sR4HCUc_4xBU73Up9OI24hIyPx0zY/edit\n",
    "\n",
    "    # for now only the vital ones\n",
    "    output_dir=\"_output\"\n",
    "    log_directory=\"_logs\"\n",
    "    n_init_lb=100\n",
    "    n_query=100 \n",
    "    alpha_opt=True\n",
    "    mode = \"query\"\n",
    "    stategy = \"AlphaMixSampling\" #EntropySampling #RandomSampling\n",
    "    model = \"mlp\"\n",
    "    customLearnerCondaEnv = \"customLearner3\"\n",
    "\n",
    "    def __init__(self, dataset, **kwargs):\n",
    "        super().__init__(dataset)\n",
    "\n",
    "        # sets new values to any default arguments passed during construction    \n",
    "        for key, value in kwargs.items():\n",
    "            if hasattr(self, key):\n",
    "                self.set_parameter(key,value)\n",
    "\n",
    "    def set_parameter(self,key,value):\n",
    "        # change member variable members. Public method that can be used outside the scope of the scope\n",
    "        if hasattr(self, key):\n",
    "            setattr(self, key, value)\n",
    "        else:\n",
    "            print(f'Argument {key} does not exist. Value of {value} does not set any of the member values of the customSampler class')\n",
    "\n",
    "    def query(self, discard_n_candidates=10):\n",
    "        # under active development\n",
    "        round = getLastRound(self.db)\n",
    "\n",
    "        # if (round == -1):                                                   # random sampling when labels are absent\n",
    "        #     ids = getLabelledIds(self.db, round)\n",
    "        #     return random.sample(ids, labels_per_round)\n",
    "        # elif (round >= 0):\n",
    "        curRound = getLastRound(self.db)\n",
    "\n",
    "        csvQue=os.path.join(output_queDir,\"queries_\"+str(curRound)+\".csv\")\n",
    "\n",
    "        arguments = f\"--data_name {DATASET_NAME} --data_dir {import_dir} --mode {self.mode} --query_out {csvQue} --n_query {labels_per_round} --model {model_name} --strategy {strategy} --alpha_opt\"\n",
    "        subprocess.run(f\"\"\"source ~/miniconda3/etc/profile.d/conda.sh\n",
    "                    conda activate {self.customLearnerCondaEnv} \n",
    "                    python alpha_mix_active_learning/_main.py {arguments}\"\"\",\n",
    "                    shell=True, executable='/bin/bash', check=True)\n",
    "        \n",
    "        queryOut = pd.read_csv(csvQue,index_col=0)\n",
    "        \n",
    "        return queryOut[\"query_results\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling Interface Objects\n",
    "\n",
    "Human labeling with Pixano Annotator is built-in, here we specify an Auto Annotator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoAnnotator(BaseAnnotator):\n",
    "    # custom annotation function\n",
    "    # as we have ground truth for MNIST, we can autofill\n",
    "    def annotate(self, round):\n",
    "        candidates = getTaggedIds(self.db, round)\n",
    "        db_tbl = mnist_db.open_table(\"db\")\n",
    "        custom_update(db_tbl, f\"id in ({ddb_str(candidates)})\", 'label', [str(Y_train[id_to_idx(candidate)]) for candidate in sorted(candidates, key=natural_key)])\n",
    "        print(f\"AutoAnnotator: round {round} annotated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanceTable(db)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_db.open_table(\"db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orchestrator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on all data, don't reset weights before each training round (it may overfit on first rounds data)\n",
    "# myTrainer = SimpleTrainer(mnist_db, model, (x_test, y_test))\n",
    "\n",
    "# train on all data, reset weights before each training round\n",
    "#myTrainer = SimpleTrainer(mnist_db, model, (x_test, y_test), avoid_overfit=True) \n",
    "\n",
    "# train on candidates data (without resetting weights obviously)\n",
    "# myTrainer = IncrementalTrainer(mnist_db, model, (x_test, y_test))\n",
    "myTrainer = customTrainer(mnist_db, model, (x_test, y_test))\n",
    "\n",
    "# randomSampler = RandomSampler(mnist_db)\n",
    "customSampler = customSampler(mnist_db,n_query=200, irrelevant=5)\n",
    "\n",
    "autofillAnnotator = AutoAnnotator(mnist_db)\n",
    "\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################################### INTERNAL GPU CHECK ######################################################\n",
      "\n",
      "\n",
      "is_available  True\n",
      "device_count  1\n",
      "current device  0\n",
      "cuda.device  <torch.cuda.device object at 0x7f5a9a374790>\n",
      "device name  NVIDIA GeForce RTX 3090\n",
      "\n",
      "\n",
      "################################################################################################################################\n",
      "\n",
      "\n",
      "Namespace(mode='query', data_name='MNIST_pixano_v7', n_label=10, data_dir='/home/melissap/_pixano_datasets_/MNIST_pixano_v7', train_out=None, query_out='/home/melissap/Desktop/LAGO_43integrationDemo/pixano/temp_data/output_queries/queries_-1.csv', log_dir='_logs', save_checkpoints=False, save_images=False, print_to_file=False, seeds=[1, 10, 100, 1000, 10000], init_lb_method='general_random', n_query=100, query_growth_ratio=1, strategy='AlphaMixSampling', n_drop=5, eps=0.05, max_iter=50, alpha_cap=0.03125, alpha_opt=True, alpha_closed_form_approx=True, alpha_learning_rate=0.1, alpha_clf_coef=1.0, alpha_l2_coef=0.01, alpha_learning_iters=5, alpha_learn_batch_size=1000000)\n",
      "Round 0 tagged\n",
      "113 candidates on round 0\n",
      "AutoAnnotator: round 0 annotated.\n",
      "\n",
      "\n",
      "###################################################### INTERNAL GPU CHECK ######################################################\n",
      "\n",
      "\n",
      "is_available  True\n",
      "device_count  1\n",
      "current device  0\n",
      "cuda.device  <torch.cuda.device object at 0x7fbe83198640>\n",
      "device name  NVIDIA GeForce RTX 3090\n",
      "\n",
      "\n",
      "################################################################################################################################\n",
      "\n",
      "\n",
      "Namespace(mode='train', data_name='MNIST_pixano_v7', n_label=10, data_dir='/home/melissap/_pixano_datasets_/MNIST_pixano_v7', train_out='/home/melissap/Desktop/LAGO_43integrationDemo/pixano/temp_data/output_accuracy/accuracy.csv', query_out='path to the file', log_dir='_logs', save_checkpoints=False, save_images=False, print_to_file=False, seeds=[1, 10, 100, 1000, 10000], init_lb_method='general_random', n_query=100, query_growth_ratio=1, strategy='AlphaMixSampling', n_drop=5, eps=0.05, max_iter=50, alpha_cap=0.03125, alpha_opt=True, alpha_closed_form_approx=True, alpha_learning_rate=0.1, alpha_clf_coef=1.0, alpha_l2_coef=0.01, alpha_learning_iters=5, alpha_learn_batch_size=1000000)\n",
      "number of labeled pool: 699\n",
      "number of unlabeled pool: 59301\n",
      "number of validation pool: 0\n",
      "number of testing pool: 101\n",
      "Using cuda device.\n",
      "MNIST_pixano_v7\n",
      "SEED 1\n",
      "AlphaMixSampling\n",
      "Adam optimizer...\n",
      "Training started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [00:40<00:55,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached max accuracy at epoch 39 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [00:41<01:05,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0\n",
      "testing accuracy 0.06930693069306931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 6.93069306930693}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_learner = Learner(\n",
    "    db=mnist_db,\n",
    "    trainer=myTrainer,\n",
    "    sampler=customSampler,\n",
    "    custom_annotator=autofillAnnotator,\n",
    "    new_al=True,\n",
    "    verbose=0\n",
    ")\n",
    "candidates = init_learner.query(round, labels_per_round)\n",
    "init_learner.annotate(round)\n",
    "init_learner.train(round, epochs=epochs)\n",
    "\n",
    "# round += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################################### INTERNAL GPU CHECK ######################################################\n",
      "\n",
      "\n",
      "is_available  True\n",
      "device_count  1\n",
      "current device  0\n",
      "cuda.device  <torch.cuda.device object at 0x7fee18dd8610>\n",
      "device name  NVIDIA GeForce RTX 3090\n",
      "\n",
      "\n",
      "################################################################################################################################\n",
      "\n",
      "\n",
      "Namespace(mode='query', data_name='MNIST_pixano_v7', n_label=10, data_dir='/home/melissap/_pixano_datasets_/MNIST_pixano_v7', train_out=None, query_out='/home/melissap/Desktop/LAGO_43integrationDemo/pixano/temp_data/output_queries/queries_0.csv', log_dir='_logs', save_checkpoints=False, save_images=False, print_to_file=False, seeds=[1, 10, 100, 1000, 10000], init_lb_method='general_random', n_query=100, query_growth_ratio=1, strategy='AlphaMixSampling', n_drop=5, eps=0.05, max_iter=50, alpha_cap=0.03125, alpha_opt=True, alpha_closed_form_approx=True, alpha_learning_rate=0.1, alpha_clf_coef=1.0, alpha_l2_coef=0.01, alpha_learning_iters=5, alpha_learn_batch_size=1000000)\n",
      "number of labeled pool: 699\n",
      "number of unlabeled pool: 59301\n",
      "number of validation pool: 0\n",
      "number of testing pool: 101\n",
      "Using cuda device.\n",
      "Loading weights mlp_MNIST_pixano_v7_AlphaMixSampling_0_weights.pth\n",
      "MNIST_pixano_v7\n",
      "SEED 1\n",
      "AlphaMixSampling\n",
      "Round 0\n",
      "query budget: 100\n",
      "With alpha_cap set to 0.031250, number of inconsistencies: 2551\n",
      "Number of inconsistencies: 2551\n",
      "alpha_mean_mean: 1.000000\n",
      "alpha_std_mean: 0.000000\n",
      "alpha_mean_std 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/melissap/miniconda3/envs/customLearner3/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples that are misclassified and selected: 100 (100.00%)\n",
      "Log Determinant of the Gram Matrix: 445.569550\n",
      "Signed Log Determinant of the Gram Matrix: 445.569550\n",
      "Confidence: 0.346711\n",
      "Margin: 0.013365\n",
      "Predicted Entropy: 2.231691\n",
      "GT Entropy: nan\n",
      "Border Entropy: 3.573988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/melissap/miniconda3/envs/customLearner3/lib/python3.10/site-packages/scipy/stats/_entropy.py:133: RuntimeWarning: invalid value encountered in divide\n",
      "  pk = 1.0*pk / np.sum(pk, axis=axis, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0 tagged\n"
     ]
    }
   ],
   "source": [
    "candidates = init_learner.query(round, labels_per_round)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add some auto-annotation rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################################### INTERNAL GPU CHECK ######################################################\n",
      "\n",
      "\n",
      "is_available  True\n",
      "device_count  1\n",
      "current device  0\n",
      "cuda.device  <torch.cuda.device object at 0x7f17f2fa0550>\n",
      "device name  NVIDIA GeForce RTX 3090\n",
      "\n",
      "\n",
      "################################################################################################################################\n",
      "\n",
      "\n",
      "Namespace(mode='query', data_name='MNIST_pixano_v7', n_label=10, data_dir='/home/melissap/_pixano_datasets_/MNIST_pixano_v7', train_out=None, query_out='/home/melissap/Desktop/LAGO_43integrationDemo/pixano/temp_data/output_queries/queries_0.csv', log_dir='_logs', save_checkpoints=False, save_images=False, print_to_file=False, seeds=[1, 10, 100, 1000, 10000], init_lb_method='general_random', n_query=100, query_growth_ratio=1, strategy='AlphaMixSampling', n_drop=5, eps=0.05, max_iter=50, alpha_cap=0.03125, alpha_opt=True, alpha_closed_form_approx=True, alpha_learning_rate=0.1, alpha_clf_coef=1.0, alpha_l2_coef=0.01, alpha_learning_iters=5, alpha_learn_batch_size=1000000)\n",
      "number of labeled pool: 699\n",
      "number of unlabeled pool: 59301\n",
      "number of validation pool: 0\n",
      "number of testing pool: 101\n",
      "Using cuda device.\n",
      "Loading weights mlp_MNIST_pixano_v7_AlphaMixSampling_0_weights.pth\n",
      "MNIST_pixano_v7\n",
      "SEED 1\n",
      "AlphaMixSampling\n",
      "Round 0\n",
      "query budget: 100\n",
      "With alpha_cap set to 0.031250, number of inconsistencies: 2551\n",
      "Number of inconsistencies: 2551\n",
      "alpha_mean_mean: 1.000000\n",
      "alpha_std_mean: 0.000000\n",
      "alpha_mean_std 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/melissap/miniconda3/envs/customLearner3/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples that are misclassified and selected: 100 (100.00%)\n",
      "Log Determinant of the Gram Matrix: 445.569550\n",
      "Signed Log Determinant of the Gram Matrix: 445.569550\n",
      "Confidence: 0.346711\n",
      "Margin: 0.013365\n",
      "Predicted Entropy: 2.231691\n",
      "GT Entropy: nan\n",
      "Border Entropy: 3.573988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/melissap/miniconda3/envs/customLearner3/lib/python3.10/site-packages/scipy/stats/_entropy.py:133: RuntimeWarning: invalid value encountered in divide\n",
      "  pk = 1.0*pk / np.sum(pk, axis=axis, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0 tagged\n",
      "236 candidates on round 0\n",
      "AutoAnnotator: round 0 annotated.\n",
      "\n",
      "\n",
      "###################################################### INTERNAL GPU CHECK ######################################################\n",
      "\n",
      "\n",
      "is_available  True\n",
      "device_count  1\n",
      "current device  0\n",
      "cuda.device  <torch.cuda.device object at 0x7f7b54d88550>\n",
      "device name  NVIDIA GeForce RTX 3090\n",
      "\n",
      "\n",
      "################################################################################################################################\n",
      "\n",
      "\n",
      "Namespace(mode='train', data_name='MNIST_pixano_v7', n_label=10, data_dir='/home/melissap/_pixano_datasets_/MNIST_pixano_v7', train_out='/home/melissap/Desktop/LAGO_43integrationDemo/pixano/temp_data/output_accuracy/accuracy.csv', query_out='path to the file', log_dir='_logs', save_checkpoints=False, save_images=False, print_to_file=False, seeds=[1, 10, 100, 1000, 10000], init_lb_method='general_random', n_query=100, query_growth_ratio=1, strategy='AlphaMixSampling', n_drop=5, eps=0.05, max_iter=50, alpha_cap=0.03125, alpha_opt=True, alpha_closed_form_approx=True, alpha_learning_rate=0.1, alpha_clf_coef=1.0, alpha_l2_coef=0.01, alpha_learning_iters=5, alpha_learn_batch_size=1000000)\n",
      "number of labeled pool: 799\n",
      "number of unlabeled pool: 59201\n",
      "number of validation pool: 0\n",
      "number of testing pool: 124\n",
      "Using cuda device.\n",
      "MNIST_pixano_v7\n",
      "SEED 1\n",
      "AlphaMixSampling\n",
      "Adam optimizer...\n",
      "Training started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [00:37<01:03,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached max accuracy at epoch 37 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [00:38<01:05,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0\n",
      "testing accuracy 0.08064516129032258\n",
      "\n",
      "\n",
      "###################################################### INTERNAL GPU CHECK ######################################################\n",
      "\n",
      "\n",
      "is_available  True\n",
      "device_count  1\n",
      "current device  0\n",
      "cuda.device  <torch.cuda.device object at 0x7fe8883b4640>\n",
      "device name  NVIDIA GeForce RTX 3090\n",
      "\n",
      "\n",
      "################################################################################################################################\n",
      "\n",
      "\n",
      "Namespace(mode='query', data_name='MNIST_pixano_v7', n_label=10, data_dir='/home/melissap/_pixano_datasets_/MNIST_pixano_v7', train_out=None, query_out='/home/melissap/Desktop/LAGO_43integrationDemo/pixano/temp_data/output_queries/queries_0.csv', log_dir='_logs', save_checkpoints=False, save_images=False, print_to_file=False, seeds=[1, 10, 100, 1000, 10000], init_lb_method='general_random', n_query=100, query_growth_ratio=1, strategy='AlphaMixSampling', n_drop=5, eps=0.05, max_iter=50, alpha_cap=0.03125, alpha_opt=True, alpha_closed_form_approx=True, alpha_learning_rate=0.1, alpha_clf_coef=1.0, alpha_l2_coef=0.01, alpha_learning_iters=5, alpha_learn_batch_size=1000000)\n",
      "number of labeled pool: 799\n",
      "number of unlabeled pool: 59201\n",
      "number of validation pool: 0\n",
      "number of testing pool: 124\n",
      "Using cuda device.\n",
      "Loading weights mlp_MNIST_pixano_v7_AlphaMixSampling_0_weights.pth\n",
      "MNIST_pixano_v7\n",
      "SEED 1\n",
      "AlphaMixSampling\n",
      "Round 0\n",
      "query budget: 100\n",
      "With alpha_cap set to 0.031250, number of inconsistencies: 2620\n",
      "Number of inconsistencies: 2620\n",
      "alpha_mean_mean: 1.000000\n",
      "alpha_std_mean: 0.000000\n",
      "alpha_mean_std 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/melissap/miniconda3/envs/customLearner3/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples that are misclassified and selected: 100 (100.00%)\n",
      "Log Determinant of the Gram Matrix: 445.067169\n",
      "Signed Log Determinant of the Gram Matrix: 445.067169\n",
      "Confidence: 0.341889\n",
      "Margin: 0.012122\n",
      "Predicted Entropy: 2.194269\n",
      "GT Entropy: nan\n",
      "Border Entropy: 3.408954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/melissap/miniconda3/envs/customLearner3/lib/python3.10/site-packages/scipy/stats/_entropy.py:133: RuntimeWarning: invalid value encountered in divide\n",
      "  pk = 1.0*pk / np.sum(pk, axis=axis, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 tagged\n",
      "119 candidates on round 1\n",
      "AutoAnnotator: round 1 annotated.\n",
      "\n",
      "\n",
      "###################################################### INTERNAL GPU CHECK ######################################################\n",
      "\n",
      "\n",
      "is_available  True\n",
      "device_count  1\n",
      "current device  0\n",
      "cuda.device  <torch.cuda.device object at 0x7f599a9945b0>\n",
      "device name  NVIDIA GeForce RTX 3090\n",
      "\n",
      "\n",
      "################################################################################################################################\n",
      "\n",
      "\n",
      "Namespace(mode='train', data_name='MNIST_pixano_v7', n_label=10, data_dir='/home/melissap/_pixano_datasets_/MNIST_pixano_v7', train_out='/home/melissap/Desktop/LAGO_43integrationDemo/pixano/temp_data/output_accuracy/accuracy.csv', query_out='path to the file', log_dir='_logs', save_checkpoints=False, save_images=False, print_to_file=False, seeds=[1, 10, 100, 1000, 10000], init_lb_method='general_random', n_query=100, query_growth_ratio=1, strategy='AlphaMixSampling', n_drop=5, eps=0.05, max_iter=50, alpha_cap=0.03125, alpha_opt=True, alpha_closed_form_approx=True, alpha_learning_rate=0.1, alpha_clf_coef=1.0, alpha_l2_coef=0.01, alpha_learning_iters=5, alpha_learn_batch_size=1000000)\n",
      "number of labeled pool: 899\n",
      "number of unlabeled pool: 59101\n",
      "number of validation pool: 0\n",
      "number of testing pool: 143\n",
      "Using cuda device.\n",
      "MNIST_pixano_v7\n",
      "SEED 1\n",
      "AlphaMixSampling\n",
      "Adam optimizer...\n",
      "Loading weights mlp_MNIST_pixano_v7_AlphaMixSampling_0_weights.pth\n",
      " Print the weights of the model to ensure that weights are loaded \n",
      "Training started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [00:18<01:37,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached max accuracy at epoch 16 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [00:19<01:41,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0\n",
      "testing accuracy 0.06993006993006994\n",
      "\n",
      "\n",
      "###################################################### INTERNAL GPU CHECK ######################################################\n",
      "\n",
      "\n",
      "is_available  True\n",
      "device_count  1\n",
      "current device  0\n",
      "cuda.device  <torch.cuda.device object at 0x7f0f8218c580>\n",
      "device name  NVIDIA GeForce RTX 3090\n",
      "\n",
      "\n",
      "################################################################################################################################\n",
      "\n",
      "\n",
      "Namespace(mode='query', data_name='MNIST_pixano_v7', n_label=10, data_dir='/home/melissap/_pixano_datasets_/MNIST_pixano_v7', train_out=None, query_out='/home/melissap/Desktop/LAGO_43integrationDemo/pixano/temp_data/output_queries/queries_1.csv', log_dir='_logs', save_checkpoints=False, save_images=False, print_to_file=False, seeds=[1, 10, 100, 1000, 10000], init_lb_method='general_random', n_query=100, query_growth_ratio=1, strategy='AlphaMixSampling', n_drop=5, eps=0.05, max_iter=50, alpha_cap=0.03125, alpha_opt=True, alpha_closed_form_approx=True, alpha_learning_rate=0.1, alpha_clf_coef=1.0, alpha_l2_coef=0.01, alpha_learning_iters=5, alpha_learn_batch_size=1000000)\n",
      "number of labeled pool: 899\n",
      "number of unlabeled pool: 59101\n",
      "number of validation pool: 0\n",
      "number of testing pool: 143\n",
      "Using cuda device.\n",
      "Loading weights mlp_MNIST_pixano_v7_AlphaMixSampling_1_weights.pth\n",
      "MNIST_pixano_v7\n",
      "SEED 1\n",
      "AlphaMixSampling\n",
      "Round 1\n",
      "query budget: 100\n",
      "With alpha_cap set to 0.031250, number of inconsistencies: 2790\n",
      "Number of inconsistencies: 2790\n",
      "alpha_mean_mean: 1.000000\n",
      "alpha_std_mean: 0.000000\n",
      "alpha_mean_std 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/melissap/miniconda3/envs/customLearner3/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples that are misclassified and selected: 100 (100.00%)\n",
      "Log Determinant of the Gram Matrix: 469.755463\n",
      "Signed Log Determinant of the Gram Matrix: 469.755463\n",
      "Confidence: 0.360723\n",
      "Margin: 0.017427\n",
      "Predicted Entropy: 2.229457\n",
      "GT Entropy: nan\n",
      "Border Entropy: 3.380377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/melissap/miniconda3/envs/customLearner3/lib/python3.10/site-packages/scipy/stats/_entropy.py:133: RuntimeWarning: invalid value encountered in divide\n",
      "  pk = 1.0*pk / np.sum(pk, axis=axis, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 2 tagged\n",
      "119 candidates on round 2\n",
      "AutoAnnotator: round 2 annotated.\n",
      "\n",
      "\n",
      "###################################################### INTERNAL GPU CHECK ######################################################\n",
      "\n",
      "\n",
      "is_available  True\n",
      "device_count  1\n",
      "current device  0\n",
      "cuda.device  <torch.cuda.device object at 0x7f14e6598610>\n",
      "device name  NVIDIA GeForce RTX 3090\n",
      "\n",
      "\n",
      "################################################################################################################################\n",
      "\n",
      "\n",
      "Namespace(mode='train', data_name='MNIST_pixano_v7', n_label=10, data_dir='/home/melissap/_pixano_datasets_/MNIST_pixano_v7', train_out='/home/melissap/Desktop/LAGO_43integrationDemo/pixano/temp_data/output_accuracy/accuracy.csv', query_out='path to the file', log_dir='_logs', save_checkpoints=False, save_images=False, print_to_file=False, seeds=[1, 10, 100, 1000, 10000], init_lb_method='general_random', n_query=100, query_growth_ratio=1, strategy='AlphaMixSampling', n_drop=5, eps=0.05, max_iter=50, alpha_cap=0.03125, alpha_opt=True, alpha_closed_form_approx=True, alpha_learning_rate=0.1, alpha_clf_coef=1.0, alpha_l2_coef=0.01, alpha_learning_iters=5, alpha_learn_batch_size=1000000)\n",
      "number of labeled pool: 999\n",
      "number of unlabeled pool: 59001\n",
      "number of validation pool: 0\n",
      "number of testing pool: 162\n",
      "Using cuda device.\n",
      "MNIST_pixano_v7\n",
      "SEED 1\n",
      "AlphaMixSampling\n",
      "Adam optimizer...\n",
      "Loading weights mlp_MNIST_pixano_v7_AlphaMixSampling_1_weights.pth\n",
      " Print the weights of the model to ensure that weights are loaded \n",
      "Training started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [00:08<01:34,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached max accuracy at epoch 8 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [00:09<01:53,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0\n",
      "testing accuracy 0.07407407407407407\n"
     ]
    }
   ],
   "source": [
    "auto_rounds = 3\n",
    "round_size = 20\n",
    "for round in range(round, round+auto_rounds):\n",
    "    candidates = init_learner.query(round, round_size)\n",
    "    init_learner.annotate(round)\n",
    "    init_learner.train(round, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Active Learning - Human annotation with Pixano Annotator\n",
    "\n",
    "Here we use a different Learner for human annotation. Trainer Object use the same model so we keep training it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################################### INTERNAL GPU CHECK ######################################################\n",
      "\n",
      "\n",
      "is_available  True\n",
      "device_count  1\n",
      "current device  0\n",
      "cuda.device  <torch.cuda.device object at 0x7f6ab51b0610>\n",
      "device name  NVIDIA GeForce RTX 3090\n",
      "\n",
      "\n",
      "################################################################################################################################\n",
      "\n",
      "\n",
      "Namespace(mode='query', data_name='MNIST_pixano_v7', n_label=10, data_dir='/home/melissap/_pixano_datasets_/MNIST_pixano_v7', train_out=None, query_out='/home/melissap/Desktop/LAGO_43integrationDemo/pixano/temp_data/output_queries/queries_2.csv', log_dir='_logs', save_checkpoints=False, save_images=False, print_to_file=False, seeds=[1, 10, 100, 1000, 10000], init_lb_method='general_random', n_query=100, query_growth_ratio=1, strategy='AlphaMixSampling', n_drop=5, eps=0.05, max_iter=50, alpha_cap=0.03125, alpha_opt=True, alpha_closed_form_approx=True, alpha_learning_rate=0.1, alpha_clf_coef=1.0, alpha_l2_coef=0.01, alpha_learning_iters=5, alpha_learn_batch_size=1000000)\n",
      "number of labeled pool: 999\n",
      "number of unlabeled pool: 59001\n",
      "number of validation pool: 0\n",
      "number of testing pool: 162\n",
      "Using cuda device.\n",
      "Loading weights mlp_MNIST_pixano_v7_AlphaMixSampling_2_weights.pth\n",
      "MNIST_pixano_v7\n",
      "SEED 1\n",
      "AlphaMixSampling\n",
      "Round 2\n",
      "query budget: 100\n",
      "With alpha_cap set to 0.031250, number of inconsistencies: 2950\n",
      "Number of inconsistencies: 2950\n",
      "alpha_mean_mean: 1.000000\n",
      "alpha_std_mean: 0.000000\n",
      "alpha_mean_std 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/melissap/miniconda3/envs/customLearner3/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples that are misclassified and selected: 100 (100.00%)\n",
      "Log Determinant of the Gram Matrix: 473.829102\n",
      "Signed Log Determinant of the Gram Matrix: 473.829102\n",
      "Confidence: 0.360370\n",
      "Margin: 0.017940\n",
      "Predicted Entropy: 2.291274\n",
      "GT Entropy: nan\n",
      "Border Entropy: 3.559433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/melissap/miniconda3/envs/customLearner3/lib/python3.10/site-packages/scipy/stats/_entropy.py:133: RuntimeWarning: invalid value encountered in divide\n",
      "  pk = 1.0*pk / np.sum(pk, axis=axis, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 3 tagged\n",
      "116 candidates on round 3\n",
      "116 items to annotate on round 3: ['11457.jpeg', '11668.jpeg', '11850.jpeg', '44450.jpeg', '44693.jpeg', '2511.jpeg', '3616.jpeg', '4575.jpeg', '5353.jpeg', '5497.jpeg', '13553.jpeg', '13855.jpeg', '29822.jpeg', '30039.jpeg', '30264.jpeg', '6542.jpeg', '12333.jpeg', '12819.jpeg', '13081.jpeg', '13256.jpeg', '14411.jpeg', '14510.jpeg', '47535.jpeg', '47684.jpeg', '15370.jpeg', '15520.jpeg', '15658.jpeg', '50769.jpeg', '209.jpeg', '1456.jpeg', '1762.jpeg', '1788.jpeg', '17880.jpeg', '7006.jpeg', '7255.jpeg', '7873.jpeg', '8133.jpeg', '8220.jpeg', '8294.jpeg', '28838.jpeg', '29038.jpeg', '29393.jpeg', '29460.jpeg', '29569.jpeg', '51376.jpeg', '51830.jpeg', '51879.jpeg', '52136.jpeg', '16824.jpeg', '17158.jpeg', '17214.jpeg', '32806.jpeg', '33716.jpeg', '33901.jpeg', '35177.jpeg', '35416.jpeg', '36240.jpeg', '36351.jpeg', '36426.jpeg', '2511.jpeg', '3616.jpeg', '53823.jpeg', '5353.jpeg', '5497.jpeg', '38881.jpeg', '54824.jpeg', '54964.jpeg', '18742.jpeg', '21691.jpeg', '22074.jpeg', '22354.jpeg', '23176.jpeg', '55653.jpeg', '55923.jpeg', '4575.jpeg', '20648.jpeg', '20809.jpeg', '40071.jpeg', '56563.jpeg', '56936.jpeg', '58290.jpeg', '8220.jpeg', '8294.jpeg', '24891.jpeg', '58408.jpeg', '58768.jpeg', '58946.jpeg', '59345.jpeg', '6542.jpeg', '7006.jpeg', '7255.jpeg', '7873.jpeg', '8133.jpeg', '24027.jpeg', '24156.jpeg', '42753.jpeg', '42825.jpeg', '43564.jpeg', '43990.jpeg', '59398.jpeg', '209.jpeg', '10206.jpeg', '26117.jpeg', '26327.jpeg', '26494.jpeg', '26552.jpeg', '28321.jpeg', '28462.jpeg', '46697.jpeg', '10755.jpeg', '10865.jpeg', '45236.jpeg', '45254.jpeg', '1456.jpeg', '1762.jpeg', '1788.jpeg']\n",
      "Interrupted, current round has been canceled, and round labels erased\n"
     ]
    }
   ],
   "source": [
    "pix_rounds = 3\n",
    "\n",
    "learner_pix = Learner(\n",
    "    db=mnist_db,\n",
    "    trainer=myTrainer,\n",
    "    sampler=customSampler\n",
    ")\n",
    "for round in range(round + 1, pix_rounds + round + 1):\n",
    "    candidates = learner_pix.query(round , \"pix_round_size - defined_within_class\")\n",
    "    # if aborted, we must untag the current round \n",
    "    try:\n",
    "        learner_pix.annotate(round)\n",
    "    except KeyboardInterrupt:\n",
    "        learner_pix.untagRound(round)\n",
    "        round = round - 1\n",
    "        print(\"Interrupted, current round has been canceled, and round labels erased\")\n",
    "        break\n",
    "    result = learner_pix.train(round, epochs=epochs)\n",
    "    print(\"result\", result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 ('pixano')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6604ca948f4575fb1939f96f2cd7df5de428f245d6855ef61050d788c6a2a026"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
