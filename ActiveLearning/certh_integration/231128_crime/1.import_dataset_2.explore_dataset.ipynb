{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIn this notebook we will convert the MNIST dataset into Pixano Format\\n\\nNote: For running, activate the pixano env\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "In this notebook we will convert the CIFAR10 dataset into Pixano Format\n",
    "and we will augment the dataset by one more class (guns) using the G\n",
    "\n",
    "Note: For running, activate the pixano env\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE : Before running this notebook, set the value for the following variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The root dir name of the current repo (i.e. pixano or pixano-main etc.)\n",
    "ROOTDIR='pixano'\n",
    "# name of the dataset\n",
    "DATASET_NAME=\"CIFAR11_guns_pixano_v1\"\n",
    "# directory where the raw cifar11 dataset will be saved to be transformed latter (images), and also to be used by the active learning auto-annotator (labels)\n",
    "datasets_dir=\"/home/melissap/Desktop/LAGO/3.githubs/integration/datasets\"\n",
    "# directory in which the transformed cifar11 dataset will be saved to be used by Pixano\n",
    "library_dir=\"/home/melissap/_pixano_datasets_\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ... the rest of the notebook should run without any code adjustments/modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchvision import datasets\n",
    "from dowload_GunDataset import getGunDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting parent dir :  /home/melissap/Desktop/LAGO_43integrationDemo/pixano\n"
     ]
    }
   ],
   "source": [
    "def insertRootDir(ROOTDIR='pixano'):\n",
    "    pardir=os.path.dirname(os.path.realpath('__file__'))\n",
    "\n",
    "    found = False\n",
    "    potential_root_dir = os.path.basename(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.realpath('__file__'))))))\n",
    "\n",
    "    while(os.path.basename(pardir)!=ROOTDIR):\n",
    "\n",
    "        # print(pardir)\n",
    "        pardir=os.path.dirname(pardir)\n",
    "        \n",
    "\n",
    "        if (os.path.basename(pardir) == ROOTDIR):\n",
    "            found = True\n",
    "            break\n",
    "        if (pardir == \"/\" ):\n",
    "            break\n",
    "    \n",
    "    if found:\n",
    "        print(\"Inserting parent dir : \",pardir)\n",
    "        sys.path.insert(0,pardir)\n",
    "        return pardir\n",
    "    else:\n",
    "        print(f\"ROOTDIR NOT FOUND. You may have to change ROOTDIR variable from : '{ROOTDIR}' to '{potential_root_dir}'\")\n",
    "        return \"_NOT_FOUND_\"\n",
    "\n",
    "ROOTDIR = insertRootDir(ROOTDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/melissap/miniconda3/envs/pixano_env/lib/python3.10/site-packages/pixano/apps/explorer/dist/assets\n"
     ]
    }
   ],
   "source": [
    "from pixano.apps import Explorer\n",
    "from pixano.data import ImageImporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed( 1 )\n",
    "\n",
    "# local directory sto store the raw dataset\n",
    "cifar_dir=Path(os.path.join(datasets_dir,\"CIFAR11\"))\n",
    "\n",
    "def get_CIFAR11(data_dir):\n",
    "\n",
    "    framecounter = 0 \n",
    "\n",
    "    image_dir = os.path.join(data_dir,\"images\")\n",
    "    annotation_dir = os.path.join(data_dir,\"annotations\")\n",
    "    train_imdir = os.path.join(image_dir,\"train\")\n",
    "    val_imdir = os.path.join(image_dir,\"val\")\n",
    "    test_imdir = os.path.join(image_dir,\"test\")\n",
    "    \n",
    "    raw_downloaDir = os.path.join(data_dir,\"raw_dataset\")\n",
    "    \n",
    "    train_anfile = os.path.join(annotation_dir,\"train.csv\")\n",
    "    val_anfile = os.path.join(annotation_dir,\"val.csv\") # not used\n",
    "    test_anfile = os.path.join(annotation_dir,\"test.csv\")\n",
    "    \n",
    "    # if True:\n",
    "    if os.path.isdir(image_dir) and os.path.isdir(annotation_dir):\n",
    "       pass\n",
    "    else: \n",
    "        try:\n",
    "            os.makedirs(image_dir)\n",
    "            os.makedirs(annotation_dir)\n",
    "            os.makedirs(train_imdir)\n",
    "            os.makedirs(val_imdir)\n",
    "            os.makedirs(test_imdir)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # GET CIFAR10\n",
    "        raw_tr = datasets.CIFAR10(raw_downloaDir, train=True, download=True)\n",
    "        raw_te = datasets.CIFAR10(raw_downloaDir, train=False, download=True)\n",
    "        CF_X_tr = raw_tr.data\n",
    "        CF_Y_tr = raw_tr.targets\n",
    "        CF_X_te = raw_te.data\n",
    "        CF_Y_te = raw_te.targets\n",
    "\n",
    "        destination_tar = os.path.join(data_dir,\"gun-dataset.tar.gz\")\n",
    "        \n",
    "        # download the guns dataset\n",
    "        GN_dataset_dir = getGunDataset(destination_tar)\n",
    "        GN_tr_dir = os.path.join(GN_dataset_dir,\"train\")\n",
    "        GN_te_dir = os.path.join(GN_dataset_dir,\"test\")\n",
    "\n",
    "        # convert guns dataset - read, resize, to_numpy\n",
    "        GN_X_tr = [np.array(Image.open(os.path.join(GN_tr_dir,im)).resize((32,32), Image.Resampling.LANCZOS)) for im in os.listdir(GN_tr_dir)]\n",
    "        GN_X_te = [np.array(Image.open(os.path.join(GN_te_dir,im)).resize((32,32), Image.Resampling.LANCZOS)) for im in os.listdir(GN_te_dir)]\n",
    "        GN_Y_tr = [int(10) for im in range(len(GN_X_tr))] # 10 classes on CIFAR (0 .. 9). The new one, has one-hot encoding equal to number of 10 (the 11th class).\n",
    "        GN_Y_te = [int(10) for im in range(len(GN_X_te))]\n",
    "\n",
    "        # subsampling to make a uniform distribution across all classes, including the new class inserted (i.e. GUNs)\n",
    "        cf_num_classes = 10\n",
    "        tr_num_samples = len(CF_Y_tr) // cf_num_classes # == num samples per class on the training set\n",
    "        tr_subsampling_idxs = random.sample(range(0, len(GN_Y_tr)-1), tr_num_samples ) # apply subsampling on the training set\n",
    "        GN_X_tr = [GN_X_tr[i] for i in tr_subsampling_idxs]\n",
    "        GN_Y_tr = [GN_Y_tr[i] for i in tr_subsampling_idxs]\n",
    "\n",
    "        te_num_samples = len(CF_Y_te) // cf_num_classes # == 1000 samples per class on the testing set\n",
    "        # Testing split requires no subsampling. There are 1000 num samples per class in the CIFAR, and 998 num of samples in the GUNsDataset. Subsampling is skipped.\n",
    "\n",
    "        # merge the two datasets\n",
    "        X_tr = [*CF_X_tr , *GN_X_tr]\n",
    "        Y_tr = [*CF_Y_tr , *GN_Y_tr]\n",
    "        X_te = [*CF_X_te , *GN_X_te]\n",
    "        Y_te = [*CF_Y_te , *GN_Y_te]\n",
    "\n",
    "        # shuffle before saving\n",
    "        tr_shuffled_idxs = list(range(len(Y_tr)))\n",
    "        te_shuffled_idxs = list(range(len(Y_te)))\n",
    "        random.shuffle(tr_shuffled_idxs)\n",
    "        random.shuffle(te_shuffled_idxs)\n",
    "        X_tr = [X_tr[i] for i in tr_shuffled_idxs]\n",
    "        Y_tr = [Y_tr[i] for i in tr_shuffled_idxs]\n",
    "        X_te = [X_te[i] for i in te_shuffled_idxs]\n",
    "        Y_te = [Y_te[i] for i in te_shuffled_idxs]\n",
    "\n",
    "        # store frames\n",
    "        for i in range(len(X_tr)):\n",
    "            x=np.array(X_tr[i])\n",
    "            im = Image.fromarray(x)\n",
    "            savepath = os.path.join(train_imdir,str(framecounter)+\".jpeg\")\n",
    "            im.save(savepath)\n",
    "            framecounter+=1\n",
    "\n",
    "        for i in range(len(X_te)):\n",
    "            x=np.array(X_te[i])\n",
    "            im = Image.fromarray(x)\n",
    "            savepath = os.path.join(test_imdir,str(framecounter)+\".jpeg\")\n",
    "            im.save(savepath)\n",
    "            framecounter+=1\n",
    "\n",
    "        # store annotations\n",
    "        y=pd.DataFrame(np.array(Y_tr))\n",
    "        y.to_csv(train_anfile,index=False)\n",
    "            \n",
    "        y=pd.DataFrame(np.array(Y_te))\n",
    "        y.to_csv(test_anfile,index=False)\n",
    "\n",
    "        # remove raw data\n",
    "        shutil.rmtree(raw_downloaDir)\n",
    "        shutil.rmtree(GN_dataset_dir)\n",
    "        print(f'Dataset succesfull downoladed within {data_dir}, framecounter = {framecounter}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dataset information\n",
    "name = \"CIFAR11 dataset\"\n",
    "description = \"CIFAR10 : https://www.cs.toronto.edu/~kriz/cifar.html , Gun Detection Dataset : https://www.linksprite.com/gun-detection-datasets/\"\n",
    "splits = [\"train\", \"test\"] # \"val\",\n",
    "\n",
    "# Input information\n",
    "input_dirs = {\n",
    "    \"image\": cifar_dir / \"images\" #,\n",
    "    # \"objects\": library_dir / \"annotations\",\n",
    "}\n",
    "\n",
    "library_dir=Path(library_dir)\n",
    "import_dir = library_dir / DATASET_NAME\n",
    "\n",
    "get_CIFAR11(cifar_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function import_dataset in module pixano.data.importers.importer:\n",
      "\n",
      "import_dataset(self, input_dirs: dict[str, pathlib.Path], import_dir: pathlib.Path, portable: bool = False) -> pixano.data.dataset.Dataset\n",
      "    Import dataset to Pixano format\n",
      "    \n",
      "    Args:\n",
      "        input_dirs (dict[str, Path]): Input directories\n",
      "        import_dir (Path): Import directory\n",
      "        portable (bool, optional): True to copy or download files to import directory and use relative paths. Defaults to False.\n",
      "    \n",
      "    Returns:\n",
      "        Dataset: Imported dataset\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ImageImporter.import_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-01T12:26:34Z WARN  lance::dataset] No existing dataset at /home/melissap/_pixano_datasets_/CIFAR11_guns_pixano_v1/db.lance, it will be created\n",
      "[2023-12-01T12:26:34Z WARN  lance::dataset] No existing dataset at /home/melissap/_pixano_datasets_/CIFAR11_guns_pixano_v1/image.lance, it will be created\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd13f3740634d528bc658d3edf03241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Importing dataset: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "583de95387714def9aadc137397d78be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Copying media directories:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66945c32e1e14a53bc83fef5342bf1a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating dataset info file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71cfd51ce7f046df953413775a9a3fa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating dataset thumbnail:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<pixano.data.dataset.Dataset at 0x7f5447f60c10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importer = ImageImporter(name, description, splits)\n",
    "importer.import_dataset(input_dirs, import_dir, portable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### !ERROR: Here we found and issue. explorer doesn't return a localhost port for opening Pixano GUI. A fix is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explorer = Explorer(library_dir)\n",
    "# explorer.display()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('pixano_env3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "faa21598805a2aeab7a6cebb281d986b89a84993d64c8b80ad12581d75a6a376"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
